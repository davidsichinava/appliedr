<div class="header" style="margin-top:0 px;font-size:60%;">ITASUR: Sixth Meeting</div>

Introduction to applied statistics using R
========================================================
author: David Sichinava, Ph.D.
date: November 4, 2020
autosize: true
transition: none
css: css/style.css
font-family: 'BPG_upper'
<span style="font-weight:bold; font-family:BPG_upper;">Sixth Meeting</span>


Today's plan
========================================================

* Midterm
* Uncertainty
	+ Parameters and estimates
	+ Hypothesis testing

Midterm
========================================================
* Similar to our lab exercise with following components:
	- data transformation (0-5 points),
	- data analysis (0-8 points),
	- interpretation (0-10 points)
	- one small theoretical question (maximum a paragraph to answer) (0-2 points)
	- total: 25 points.
* Exam will open at e-learning.tsu.ge at 6 PM Tbilisi time on Wednesday, November 11th and will close in four hours (at 10 PM Tbilisi time);
* You will have to upload your work to e-learning.tsu.ge;
* These assignments are individual, that is, each of you will get an unique assignment. Please work on them _by your own_

Confidence intervals
========================================================
* Confidence interval is an interval where according to an agreed probability, there exist our parameter of interest:
* $CI(\alpha) = [\overline{X}_{n}-z_{\alpha/2}*se; \overline{X}_{n}+z_{\alpha/2}*se; ]$
* As we can see, $z$-values depend on the _type of distribution_


Analysis of experiment
========================================================
```{r, eval=FALSE}
STAR <- read.csv("STAR.csv", head = TRUE)
```

Analysis of experiment
========================================================
```{r, eval=FALSE}
n.small <-
sum(STAR$classtype == 1 & !is.na(STAR$g4reading))
est.small <- mean(STAR$g4reading[STAR$classtype == 1], na.rm = TRUE)
se.small <- sd(STAR$g4reading[STAR$classtype == 1], na.rm = TRUE) /
sqrt(n.small)
est.small
se.small
n.regular <- sum(STAR$classtype == 2 & !is.na(STAR$classtype) &
!is.na(STAR$g4reading))
```

Analysis of experiment
========================================================
```{r, eval=FALSE}
est.regular <- mean(STAR$g4reading[STAR$classtype == 2], na.rm = TRUE)
se.regular <- sd(STAR$g4reading[STAR$classtype == 2], na.rm = TRUE) /
sqrt(n.regular)
est.regular
```

Analysis of experiment
========================================================
```{r, eval=FALSE}
alpha <- 0.05

ci.small <- c(est.small - qnorm(1 - alpha / 2) * se.small,
est.small + qnorm(1 - alpha / 2) * se.small)
ci.small

ci.regular <- c(est.regular - qnorm(1 - alpha / 2) * se.regular,
est.regular + qnorm(1 - alpha / 2) * se.regular)
ci.regular
```

Analysis of experiment
========================================================
```{r, eval=FALSE}
# Sample average treatment effect of an experiment
ate.est <- est.small - est.regular
ate.se <- sqrt(se.small^2 + se.regular^2)
ate.ci <- c(ate.est - qnorm(1 - alpha / 2) * ate.se,
ate.est + qnorm(1 - alpha / 2) * ate.se)
ate.ci
```

Analysis of experiment: Student's t-test
========================================================
```{r, eval=FALSE}
c(est.small - qt(0.975, df = n.small - 1) * se.small,
est.small + qt(0.975, df = n.small - 1) * se.small)
ci.small
c(est.regular - qt(0.975, df = n.regular - 1) * se.regular,
est.regular + qt(0.975, df = n.regular - 1) * se.regular)
ci.regular

t.ci <- t.test(STAR$g4reading[STAR$classtype == 1],
STAR$g4reading[STAR$classtype == 2])
t.ci

```

Hypothesis testing
========================================================
* Hypothesis testing of a phenomenon is based on a _probability approach_,
	+ or proving whether given phenomenon is a random or not
* _Reductio ad absurdum_
* Null hypothesis $H_{0}$

Hypothesis testing
========================================================
Null hypothesis â‡’ Test statistic â‡’ Reference statistic â‡’ Calculating probability of whether a test statistic is present in  reference statistic

Hypothesis testing
========================================================
| Result |Rejecting $H_{0}$ | Retaining $H_{0}$ |
|--------|-----------|------------------|-------------------|
| $H_{0}$ True | Type I error | True        |
| $H_{0}$ False    | True       | Type II error |

Hypothesis testing
========================================================
* How do we decide whether we have to accept or reject null hypothesis?
	+ We have to quantify the degree to which the existence of a test statistic is very low, given null hypothesis
	+ p-values


Hypothesis testing
========================================================
> Little p-value, What are you trying to say, Of significance?

_Stephen T. Ziliak, Roosvelt University_


Hypothesis testing
========================================================
* Statistical significance;
* Probability of having an extreme value that is as extreme as test statistic, given null hypothesis.
* [For instance:](http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values): 
* We are checking a new COVID-19 ðŸ¦  vaccince, for which we have conducted an experiment. Imagine, that temperature decreased in the treatment group, although p-value equals to 0.04.
* What this means is that if _the faccine was ineffective (that is, null hypothesis was correct)_, we would receive a difference between treatment and control groups in the 4% of all future experiments.
* $p$-value is not a probability of making a mistake!


Hypothesis testing
========================================================
* Similar to confidence intervals, we also choose a specific level:
	+ 95% or 99%
<img src="img/neyman.PNG" alt="Drawing" style="width: 600px; display: block; margin-left: auto; margin-right: auto; margin-top: 30px;"/>

Neyman, J. (1937). Outline of a theory of statistical estimation based on the classical theory of probability. _Philosophical Transactions of the Royal Society of London._ Series A, Mathematical and Physical Sciences, 236(767), 333-380.


Hypothesis testing
========================================================
* P-values for one and two sample tests

Hypothesis testing
========================================================
* One sample t-test:
	+ Population mean equals to a particular number;
* Two samples t-test:
	+ Means of two populations are equal.

Hypothesis testing and confidence intervals
========================================================
* z-scores for confidence intervals:
	+ $\frac{\overline{X}_{n}-\mathbb{E}_{X}}{Standard\ Error}$
* z-scores for $p$-values:
	+ $\frac{\overline{X}_{n}-\mu_{0}}{Standard\ Error}$


STAR-project
========================================================
One sample t-test
```{r, eval=FALSE}
t.test(STAR$g4reading, mu = 710)
```

STAR-project
========================================================
Two samples t-test
```{r, eval=FALSE}
t.test(STAR$g4reading[STAR$classtype == 1],
STAR$g4reading[STAR$classtype == 2])

```

Labor marker discrimination
========================================================

```{r, eval=FALSE}
resume <- read.csv("resume.csv")
x <- table(resume$race, resume$call)
prop.test(x, alternative = "greater")
```

